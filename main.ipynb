{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 35px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://images.pexels.com/photos/7078619/pexels-photo-7078619.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:black'><strong>EABL STOCK PRICE PREDICTION </strong></span></b> </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> <span style='color:#16C2D5'>|</span> Business Objectives</b>\n",
    "1. Build a robust time series model leveraging market indicators to forecast future EABL stock prices. \n",
    "2. Investigate viability of investing in EABL stock prices. \n",
    "3. Build an anomally detection system to identify unusual or unexpected patterns in EABL stock prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    " \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA NDERSTANDING\n",
    "1. Load and inspect the data\n",
    "\n",
    "   Check the structure and completeness of the dataset.\n",
    "\n",
    "2. Data preprocessing \n",
    "\n",
    "   Handle missing values, convert data types if necessary, and set the date column as the index for time series analysis.\n",
    "\n",
    "3. Volatility Insights\n",
    "\n",
    "   Investigate and model the volatility of EABL stock prices over time.\n",
    "\n",
    "4. Abnormal Trade Volume Analysis\n",
    "\n",
    "   Identify and analyze spikes or drops in trade volumes.\n",
    "\n",
    "5. Dividend Analysis\n",
    "\n",
    "   Examine the trend in dividend payouts.\n",
    "\n",
    "6. Time Series Decomposition\n",
    "\n",
    "   Decompose  time series into trends,seasonal and residual components to better understand the underlying patterns.\n",
    "\n",
    "7. Lag Analysis\n",
    "\n",
    "   Investigate the effects of market indicators on EABL stock prices whether their impact have a time lag \n",
    "\n",
    "8. Stock Valuation\n",
    "\n",
    "   Investigate how stock prices vary with quarterly  unemployment rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns and First 5 Rows in Merged Data:\n",
      "   Unnamed: 0       Date    Open    High    Low  Close  Average  Volume  \\\n",
      "0           0  1/31/2024  104.00  111.00  104.0  110.0   106.00   42000   \n",
      "1           1  1/30/2024  105.00  105.00  101.0  104.0   104.00   15600   \n",
      "2           2  1/29/2024  105.00  105.00   99.0  103.5   100.00  596100   \n",
      "3           3  1/26/2024  116.25  116.25  100.0  100.0   104.50   60500   \n",
      "4           4  1/25/2024  119.75  120.00  118.0  118.0   118.25    5700   \n",
      "\n",
      "   Month  Year  Day  Annual Average Inflation  12-Month Inflation   Mean  \\\n",
      "0      1  2024   31                       NaN                 6.9  161.0   \n",
      "1      1  2024   30                       NaN                 6.9  161.0   \n",
      "2      1  2024   29                       NaN                 6.9  162.0   \n",
      "3      1  2024   26                       NaN                 6.9  162.0   \n",
      "4      1  2024   25                       NaN                 6.9  163.0   \n",
      "\n",
      "   Amount  Dividends per share  Earnings Per Share  \n",
      "0    1.00                  0.0                 NaN  \n",
      "1    1.00                  0.0                 NaN  \n",
      "2    1.00                  0.0                 NaN  \n",
      "3    1.00                  0.0                 NaN  \n",
      "4    1.75                  0.0                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# Loading and Previewing the datasets\n",
    "merged_data = pd.read_csv('Data/final_merge.csv')\n",
    "\n",
    "print(\"\\nColumns and First 5 Rows in Merged Data:\")\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "Unnamed: 0                    0\n",
      "Date                          0\n",
      "Open                          0\n",
      "High                          0\n",
      "Low                           0\n",
      "Close                         0\n",
      "Average                       0\n",
      "Volume                        0\n",
      "Month                         0\n",
      "Year                          0\n",
      "Day                           0\n",
      "Annual Average Inflation     21\n",
      "12-Month Inflation            0\n",
      "Mean                         12\n",
      "Amount                      112\n",
      "Dividends per share           0\n",
      "Earnings Per Share           21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the final_merge.csv\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(merged_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset exhibits some missing values in key columns. The 'Annual Average Inflation' column has 21 missing entries, suggesting that information regarding the average annual inflation rate for those specific periods is unavailable. Additionally, the 'Mean' column has 12 missing values, indicating a lack of mean exchange rates for those corresponding dates. Furthermore, the 'Amount' column shows 112 missing values, implying that the exact monetary amount associated with certain transactions or financial events is not recorded. Lastly, the 'Earnings Per Share' column has 21 missing values, suggesting that earnings per share information is absent for some instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4353 entries, 0 to 4352\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                4353 non-null   int64  \n",
      " 1   Date                      4353 non-null   object \n",
      " 2   Open                      4353 non-null   float64\n",
      " 3   High                      4353 non-null   float64\n",
      " 4   Low                       4353 non-null   float64\n",
      " 5   Close                     4353 non-null   float64\n",
      " 6   Average                   4353 non-null   float64\n",
      " 7   Volume                    4353 non-null   int64  \n",
      " 8   Month                     4353 non-null   int64  \n",
      " 9   Year                      4353 non-null   int64  \n",
      " 10  Day                       4353 non-null   int64  \n",
      " 11  Annual Average Inflation  4353 non-null   float64\n",
      " 12  12-Month Inflation        4353 non-null   float64\n",
      " 13  Mean                      4353 non-null   float64\n",
      " 14  Amount                    4353 non-null   float64\n",
      " 15  Dividends per share       4353 non-null   float64\n",
      " 16  Earnings Per Share        4353 non-null   float64\n",
      "dtypes: float64(11), int64(5), object(1)\n",
      "memory usage: 578.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'Annual Average Inflation' with the mean\n",
    "merged_data['Annual Average Inflation'].fillna(merged_data['Annual Average Inflation'].mean(), inplace=True)\n",
    "\n",
    "# Fill missing values in 'Mean' with the mean\n",
    "merged_data['Mean'].fillna(merged_data['Mean'].mean(), inplace=True)\n",
    "\n",
    "# Fill missing values in 'Amount' with the median\n",
    "merged_data['Amount'].fillna(merged_data['Amount'].median(), inplace=True)\n",
    "\n",
    "# Fill missing values in 'Earnings Per Share' with the mean\n",
    "merged_data['Earnings Per Share'].fillna(merged_data['Earnings Per Share'].mean(), inplace=True)\n",
    "\n",
    "# Display the cleaned dataset info\n",
    "print(\"Cleaned Dataset Info:\")\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values in the 'Annual Average Inflation,' 'Mean,' 'Amount,' and 'Earnings Per Share' columns have been successfully addressed through imputation. For the 'Annual Average Inflation' column, the missing values were filled with the mean of the available data, ensuring that the imputed values maintain the general trend of inflation. Similarly, the missing values in the 'Mean' column were imputed with the mean of the existing data, providing representative values for exchange rates during those periods. The 'Amount' column, which denotes monetary values, had missing entries filled with the median to minimize the impact of potential outliers on imputed values. Lastly, the 'Earnings Per Share' column was imputed with the mean, providing estimated values for missing earnings information. As a result of these imputation strategies, the dataset now contains 4353 entries with no missing values, enhancing its completeness and enabling a more comprehensive exploration and analysis of the financial and economic indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime format\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4353 entries, 0 to 4352\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Unnamed: 0                4353 non-null   int64         \n",
      " 1   Date                      4353 non-null   datetime64[ns]\n",
      " 2   Open                      4353 non-null   float64       \n",
      " 3   High                      4353 non-null   float64       \n",
      " 4   Low                       4353 non-null   float64       \n",
      " 5   Close                     4353 non-null   float64       \n",
      " 6   Average                   4353 non-null   float64       \n",
      " 7   Volume                    4353 non-null   int64         \n",
      " 8   Month                     4353 non-null   int64         \n",
      " 9   Year                      4353 non-null   int64         \n",
      " 10  Day                       4353 non-null   int64         \n",
      " 11  Annual Average Inflation  4353 non-null   float64       \n",
      " 12  12-Month Inflation        4353 non-null   float64       \n",
      " 13  Mean                      4353 non-null   float64       \n",
      " 14  Amount                    4353 non-null   float64       \n",
      " 15  Dividends per share       4353 non-null   float64       \n",
      " 16  Earnings Per Share        4353 non-null   float64       \n",
      " 17  Day_of_Week               4353 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(11), int64(6)\n",
      "memory usage: 612.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Extract days, months, and years from the 'Date' column\n",
    "merged_data['Day_of_Week'] = merged_data['Date'].dt.dayofweek\n",
    "merged_data['Month'] = merged_data['Date'].dt.month\n",
    "merged_data['Year'] = merged_data['Date'].dt.year\n",
    "\n",
    "# Display the updated dataset info\n",
    "print(\"Updated Dataset Info:\")\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows with Rolling Averages:\n",
      "        Date  Close  Close_MA\n",
      "0 2024-01-31  110.0       NaN\n",
      "1 2024-01-30  104.0       NaN\n",
      "2 2024-01-29  103.5       NaN\n",
      "3 2024-01-26  100.0       NaN\n",
      "4 2024-01-25  118.0     107.1\n"
     ]
    }
   ],
   "source": [
    "# Compute rolling averages for numerical columns to capture trends over time\n",
    "window_size = 5\n",
    "merged_data['Close_MA'] = merged_data['Close'].rolling(window=window_size).mean()\n",
    "\n",
    "print(\"First few rows with Rolling Averages:\")\n",
    "print(merged_data[['Date', 'Close', 'Close_MA']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used the rolling average to smooth out short-term fluctuations and highlight longer-term trends in the 'Close' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       110.000000\n",
       "1       108.375000\n",
       "2       103.929555\n",
       "3       103.596682\n",
       "4       103.710724\n",
       "           ...    \n",
       "4348    218.960968\n",
       "4349    218.952812\n",
       "4350    218.938897\n",
       "4351    218.929589\n",
       "4352    218.927385\n",
       "Name: VWAP, Length: 4353, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Volume Weighted Average Price (VWAP) which considers both price and volume\n",
    "merged_data['VWAP'] = (merged_data['Close'] * merged_data['Volume']).cumsum() / merged_data['Volume'].cumsum()\n",
    "merged_data['VWAP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'VWAP' (Volume Weighted Average Price) values in the displayed results represent the average price at which the East Africa Breweries Limited (EABL) stock has been traded, taking into account both the closing prices and the corresponding trading volumes. \n",
    "VWAP is a significant metric in financial analysis, helping traders and investors understand the average price levels at which a stock has been transacted, factoring in trading activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             NaN\n",
       "1       -5.454545\n",
       "2       -0.480769\n",
       "3       -3.381643\n",
       "4       18.000000\n",
       "          ...    \n",
       "4348     0.714286\n",
       "4349    -0.709220\n",
       "4350     1.428571\n",
       "4351    -1.408451\n",
       "4352     2.142857\n",
       "Name: Close_Pct_Change, Length: 4353, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the percentage change for relevant columns\n",
    "merged_data['Close_Pct_Change'] = merged_data['Close'].pct_change() * 100\n",
    "merged_data['Close_Pct_Change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting 'Close_Pct_Change' column contains the percentage change in the closing prices of the EABL stock for each day compared to the previous day. The first row has a NaN (Not a Number) value because there is no previous day to compare with. The patterns continue for the entire dataset, providing insights into the daily percentage changes in the EABL stock's closing prices. This information is valuable for analyzing the volatility and trends in the stock's price movements over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days_Since_Last_Dividend:\n",
      "0       19753\n",
      "1       19752\n",
      "2       19751\n",
      "3       19748\n",
      "4       19747\n",
      "        ...  \n",
      "4348    13405\n",
      "4349    13404\n",
      "4350    13403\n",
      "4351    13402\n",
      "4352    13401\n",
      "Name: Days_Since_Last_Dividend, Length: 4353, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Dividends per share' column to datetime\n",
    "merged_data['Dividends per share'] = pd.to_datetime(merged_data['Dividends per share'])\n",
    "\n",
    "# Calculate time elapsed since the last dividend announcement\n",
    "merged_data['Days_Since_Last_Dividend'] = (merged_data['Date'] - merged_data['Dividends per share']).dt.days\n",
    "\n",
    "# Display the new column\n",
    "print(\"Days_Since_Last_Dividend:\")\n",
    "print(merged_data['Days_Since_Last_Dividend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Days_Since_Last_Dividend' column provides a chronological count of the number of days that have passed since the last dividend announcement for each corresponding date in your dataset. This information can be valuable for understanding the temporal patterns and intervals between dividend payments for East Africa Breweries Limited (EABL) stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4620000.0\n",
       "1        1622400.0\n",
       "2       61696350.0\n",
       "3        6050000.0\n",
       "4         672600.0\n",
       "           ...    \n",
       "4348    31880100.0\n",
       "4349    15190000.0\n",
       "4350    26980000.0\n",
       "4351    17346000.0\n",
       "4352     4361500.0\n",
       "Name: Close_Volume_Product, Length: 4353, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['Close_Volume_Product'] = merged_data['Close'] * merged_data['Volume']\n",
    "merged_data['Close_Volume_Product']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a new interaction feature called 'Close_Volume_Product' by multiplying the 'Close' and 'Volume' columns for each entry in the dataset. The resulting values represent the product of the closing stock price and the volume traded on that particular day. This interaction feature captures the combined impact of stock price and trading volume, providing a measure of the overall market activity for East Africa Breweries Limited (EABL) stocks on a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. VOLATILITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility = df['Close'].std()\n",
    "volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated volatility of 59.23 for the closing prices of EABL stock signifies the average deviation of daily closing prices from their mean. This value indicates a substantial degree of price variability, with an average deviation of approximately 59.23 units (considered in the currency of the stock). Such a level of volatility suggests that EABL stock experiences notable and frequent price fluctuations. It's important to interpret this result in the context of risk assessment, as higher volatility may imply increased uncertainty and potential challenges in predicting future price movements. Investors and analysts should consider this volatility measure along with other risk metrics to form a comprehensive understanding of the stock's historical price dynamics and associated risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical volatility\n",
    "historical_volatility = df['Close'].pct_change().std()\n",
    "historical_volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The historical volatility of approximately 2.2% for the EABL stock means that, on average, the daily percentage change in its closing price over the specified historical period is 2.2%. This measure provides insights into the stock's past price fluctuations, serving as an indicator of its market risk. A higher historical volatility suggests a more variable and potentially riskier market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average True Range\n",
    "from ta.volatility import AverageTrueRange\n",
    "\n",
    "atr_window = 30 # The window size as needed\n",
    "atr = AverageTrueRange(high=df['High'], low=df['Low'], close=df['Close'], window=atr_window).average_true_range()\n",
    "\n",
    "# Print the calculated ATR values needed\n",
    "print(atr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EABL stock data's computed Average True Range (ATR) values show the degree of market volatility on each matching date. ATR values that are positive indicate rising volatility as you go back in time, whereas values that are negative indicate little to no volatility. This is helpful in figuring out periods of increased market activity and in comprehending previous stock price fluctuations. The ATR values shed light on how market volatility has changed during the historical time that the dataset covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame index is a datetime index\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Calculate Average True Range (ATR) for volatility\n",
    "df['atr'] = AverageTrueRange(high=df['High'], low=df['Low'], close=df['Close'], window=14).average_true_range()\n",
    "\n",
    "# Time series plot with volatility\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['Close'], label='EABL Stock Prices')\n",
    "plt.plot(df.index, df['atr'], label='Volatility (ATR)', color='orange') \n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price / Volatility')\n",
    "plt.title('EABL Stock Prices Over Time with Volatility')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility clustering plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['Close'], label='EABL Stock Prices')\n",
    "plt.plot(df.index, df['Close'].rolling(window=30).std(), label='Rolling Volatility (30 days)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price / Volatility')\n",
    "plt.title('Volatility Clustering in EABL Stock Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily returns\n",
    "df['Daily_Return'] = df['Close'].pct_change()\n",
    "\n",
    "# Box plot for daily returns\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.boxplot(df['Daily_Return'].dropna())\n",
    "plt.title('Box Plot of Daily Returns')\n",
    "plt.ylabel('Percentage Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lagging Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with 'Close' prices and 'Date' as the index\n",
    "df['Daily_Return'] = df['Close'].pct_change()\n",
    "\n",
    "# The lag period\n",
    "lag_period = 5\n",
    "\n",
    "# Create lagged version of the 'Daily_Return' column\n",
    "df['Daily_Return_Lagged'] = df['Daily_Return'].shift(lag_period)\n",
    "\n",
    "# Plot the original and lagged daily returns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['Daily_Return'], label='Original Daily Returns')\n",
    "plt.plot(df.index, df['Daily_Return_Lagged'], label=f'Daily Returns Lagged by {lag_period} day(s)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percentage Change')\n",
    "plt.title(f'Daily Returns and Lagged Daily Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Daily_Return'].shift(5), df['Daily_Return'], alpha=0.5)\n",
    "plt.title('Scatter Plot of Daily Returns and Lagged Daily Returns')\n",
    "plt.xlabel('Lagged Daily Returns (t-1)')\n",
    "plt.ylabel('Daily Returns (t)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_period = 5  # Adjust the lag period as needed\n",
    "plt.scatter(df['Daily_Return'].iloc[:-lag_period], df['Daily_Return'].shift(lag_period).dropna(), alpha=0.5)\n",
    "plt.title(f'Time Lag Scatter Plot (Lag Period = {lag_period})')\n",
    "plt.xlabel('Daily Returns (t - Lag Period)')\n",
    "plt.ylabel(f'Daily Returns (t)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
